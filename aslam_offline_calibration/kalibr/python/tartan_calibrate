#!/usr/bin/env python
print("importing libraries")

# Schweizer-Messer (swiss-army knife utils)
from matplotlib.offsetbox import DEBUG
import sm
from sm import PlotCollection

# Kalibr Modules
import aslam_cv_backend as acvb
import kalibr_common as kc
import kalibr_camera_calibration as kcc

# Python modules
import copy
import os
import numpy as np
import multiprocessing
import pylab as pl
import argparse
import sys
import random
import signal
import dill
import scipy.io
import random

from tartan_logging import TartanLogging

np.set_printoptions(suppress=True)

def initBagDataset(bagfile, topic, from_to):
    """ Reads a ROS bag dataset into a reader and returns the reader."""
    print("\tDataset:          {0}".format(bagfile))
    print("\tTopic:            {0}".format(topic))
    reader = kc.BagImageDatasetReader(bagfile, topic, bag_from_to=from_to)
    print("\tNumber of images: {0}".format(reader.numImages()))
    return reader

num_corners = np.array([])
log_file = 'log.txt'
force_all_points = False

# List of tartanlogging classes, these will be saved to a pickle for analysis at a later time
tartanlogs = []

# Camera models available to choose from.
cameraModels = { 'pinhole-radtan': acvb.DistortedPinhole,
                 'pinhole-equi':   acvb.EquidistantPinhole,
                 'pinhole-fov':    acvb.FovPinhole,
                 'omni-none':      acvb.Omni,
                 'omni-radtan':    acvb.DistortedOmni,
                 'eucm-none':      acvb.ExtendedUnified,
                 'ds-none':        acvb.DoubleSphere}

DEBUG_MODES = [
    "pointcloudprojection",
    "pinholeprojection",
    "originalprojection",
    "targetpointcloud",
    "individualprojections",
    "reprojectionpoints",
    "none"
]

REPROJECTION_MODES = [
    "pinhole",
    "homography",
    "cornerpredictor",
    "none"
]

DEFAULT_FOV = [[90],[90]]
DEFAULT_POSE = [[90],[0]]
DEFAULT_RESOLUTION = [[1000],[1000]]
DEFAULT_PROJECTION = ["cornerpredictor"]
DEFAULT_DEBUG_MODES = ["none"]

def signal_exit(signal, frame):
    sm.logWarn("Shutdown requested! (CTRL+C)")
    sys.exit(2)

def parseArgs():
    """ Parse arguments used within TartanCalib."""
    # Class for parsing Kalibr arguments.
    class KalibrArgParser(argparse.ArgumentParser):
        def error(self, message):
            self.print_help()
            sm.logError('%s' % message)
            sys.exit(2)
        def format_help(self):
            formatter = self._get_formatter()
            formatter.add_text(self.description)
            formatter.add_usage(self.usage, self._actions,
                                self._mutually_exclusive_groups)
            for action_group in self._action_groups:
                formatter.start_section(action_group.title)
                formatter.add_text(action_group.description)
                formatter.add_arguments(action_group._group_actions)
                formatter.end_section()
            formatter.add_text(self.epilog)
            return formatter.format_help()

    usage = """
    Example usage to calibrate a camera system with two cameras using an aprilgrid.

    cam0: omnidirection model with radial-tangential distortion
    cam1: pinhole model with equidistant distortion
    
    %(prog)s --models omni-radtan pinhole-equi --target aprilgrid.yaml \\
              --bag MYROSBAG.bag --topics /cam0/image_raw /cam1/image_raw

    example aprilgrid.yaml:
        target_type: 'aprilgrid'
        tagCols: 6
        tagRows: 6
        tagSize: 0.088  #m
        tagSpacing: 0.3 #percent of tagSize"""
    parser = KalibrArgParser(description='Calibrate the intrinsics and extrinsics of a camera system with non-shared overlapping field of view.', usage=usage)
    parser.add_argument('--models', nargs='+', dest='models', help='The camera model {0} to estimate'.format(list(cameraModels.keys())), required=True)

    groupSource = parser.add_argument_group('Data source')
    groupSource.add_argument('--bag', dest='bagfile', help='The bag file with the data')
    groupSource.add_argument('--topics', nargs='+', dest='topics', help='The list of image topics', required=True)
    groupSource.add_argument('--bag-from-to', metavar='bag_from_to', type=float, nargs=2, help='Use the bag data starting from up to this time [s]')

    groupTarget = parser.add_argument_group('Calibration target configuration')
    groupTarget.add_argument('--target', dest='targetYaml', help='Calibration target configuration as yaml file', required=True)

    groupImageSync = parser.add_argument_group('Image synchronization')
    groupImageSync.add_argument('--approx-sync', dest='max_delta_approxsync', type=float, default=0.02, help='Time tolerance for approximate image synchronization [s] (default: %(default)s)')

    groupCalibrator = parser.add_argument_group('Calibrator settings')
    groupCalibrator.add_argument('--qr-tol', type=float, default=0.02, dest='qrTol', help='The tolerance on the factors of the QR decomposition (default: %(default)s)')
    groupCalibrator.add_argument('--mi-tol', type=float, default=0.2, dest='miTol', help='The tolerance on the mutual information for adding an image. Higher means fewer images will be added. Use -1 to force all images. (default: %(default)s)')
    groupCalibrator.add_argument('--no-shuffle', action='store_true', dest='noShuffle', help='Do not shuffle the dataset processing order')
    groupCalibrator.add_argument('--weight-map-grid', type=int, default=0, dest='weightMapGrid', help='Grid cell size (px) for gradient-contribution weight map. 0=disabled. E.g. 15 builds a weight map that suppresses high-gradient (image edge) corners. (default: %(default)s)')
    groupCalibrator.add_argument('--weight-map-power', type=float, default=2.0, dest='weightMapPower', help='Power for weight map: w = (median_gc / gc_cell)^power. Higher = more aggressive suppression. (default: %(default)s)')
    groupCalibrator.add_argument('--weight-map-cutoff', type=float, default=0.0, dest='weightMapCutoff', help='Hard cutoff: if gc_cell > cutoff * median_gc, set weight=0 (drop corners in that cell). 0=no cutoff. (default: %(default)s)')

    groupTartan = parser.add_argument_group("Tartan settings")
    groupTartan.add_argument('--fovs', type=int,dest='l_fov', nargs='+', action='append', help='If using pinhole projection mode, this parameter represents FOV of pinhole')
    groupTartan.add_argument('--poses', type=int,dest='l_pose', nargs='+', action='append', help='If using pinhole projection mode, this parameter represents pose of pinhole')
    groupTartan.add_argument('--resolutions', type=int, dest='l_res', nargs='+', action='append', help='If using pinhole projection mode, this parameter represents resolution of pinhole')
    groupTartan.add_argument('--projections', type=str, dest='l_proj', nargs='*', action='append', help='Choose from four possible projections: pinhole, homography, cornerpredictor and none. Cornerpredictor is the autocomplete method described within the paper')
    groupTartan.add_argument('--debug-modes', type=str, dest='l_debug', nargs='*', action='append', help='Choose from 7 possible debug modes for additional debug images: pointcloudprojection, pinholeprojection, originalprojection, targetpointcloud, individualprojections, reprojectionpoints and none.')
    groupTartan.add_argument('--min-init-corners-autocomplete', type=int, default=24, dest='min_init_corners_autocomplete', help='Minimum number of corners for autocomplete, since pose of the board is otherwise too inaccurate.')
    groupTartan.add_argument('--min-tag-size-autocomplete', type=int, default=0, dest='min_tag_size_autocomplete', help='Minimum tag size (px) before autocomplete. To ensure really small tags are discarded instead of detected inaccurately.')
    groupTartan.add_argument('--correction-threshold', type=float, default=2.0, dest='correction_threshold', help='Number of pixels allowed for offset between reprojection and detection.')
    groupTartan.add_argument('--min-resize-window-size', type=int, default=2, dest='min_resize_window_size', help='Minimum window size allowed during dynamic sizing')
    groupTartan.add_argument('--max-resize-window-size', type=int, default=8, dest='max_resize_window_size', help='Maximum window size allowed during dynamic sizing')
    groupTartan.add_argument('--refine-magnitude-reject', type=float, default=2.0, dest='refine_magnitude_reject', help='')
    groupTartan.add_argument('--symmetry-refinement', action='store_true', dest='symmetry_refinement', help='Include symmetry refinement method')
    groupTartan.add_argument('--symmetry-edge-threshold', type=float, default=10.0, dest='symmetry_edge_threshold', help='')
    groupTartan.add_argument('--export-dataset-dir', type=str, default="", dest="export_dataset_dir", help='Filepath to export binary usable in generic camera model referenced in "Why Having 10000..." paper.')

    outlierSettings = parser.add_argument_group('Outlier filtering options')
    outlierSettings.add_argument('--no-outliers-removal', action='store_false', default=True, dest='removeOutliers', help='Disable corner outlier filtering')
    outlierSettings.add_argument('--no-final-filtering', action='store_false', default=True, dest='allowEndFiltering', help='Disable filtering after all views have been processed.')
    outlierSettings.add_argument('--min-views-outlier', type=int, default=20, dest='minViewOutlier', help='Number of raw views to initialize statistics (default: %(default)s)')
    outlierSettings.add_argument('--use-blakezisserman', action='store_true', dest='doBlakeZisserman', help='Enable the Blake-Zisserman m-estimator')
    outlierSettings.add_argument('--plot-outliers', action='store_true', dest='doPlotOutliers', help='Plot the detect outliers during extraction (this could be slow)')

    fisheyeSettings = parser.add_argument_group('FisheyeDetector injection (optional)')
    fisheyeSettings.add_argument('--precomputed-detections', dest='precomputedDetections',
                                  default=None, metavar='FILE.npz',
                                  help='Path to .npz produced by extract_fisheye_detections.py. '
                                       'Bypasses the C++ AprilTag detector with FisheyeDetector results.')
    fisheyeSettings.add_argument('--fisheye-conf-thr', dest='fisheyeConfThr', type=float, default=0.5,
                                  help='FisheyeDetector corner confidence threshold (default: %(default)s)')
    fisheyeSettings.add_argument('--fisheye-min-corners', dest='fisheyeMinCorners', type=int, default=4,
                                  help='Minimum accepted corners per frame (default: %(default)s)')

    outputSettings = parser.add_argument_group('Output options')
    outputSettings.add_argument('--verbose', action='store_true', dest='verbose', help='Enable (really) verbose output (disables plots)')
    outputSettings.add_argument('--show-extraction', action='store_true', dest='showextraction', help='Show the calibration target extraction. (disables plots)')
    outputSettings.add_argument('--plot', action='store_true', dest='plot', help='Plot during calibration (this could be slow).')
    outputSettings.add_argument('--dont-show-report', action='store_true', dest='dontShowReport', help='Do not show the report on screen after calibration.')
    outputSettings.add_argument('--polar_setting', type=int, default=0, dest='polarSetting', help='The way we are using polar angles of detections to improve results. 0=None, don not use. 1=set an angle threshold, under this threshold no corners will be used. 2 = bins, divide the corners into polar angle bins and give each bin a weight.')
    outputSettings.add_argument('--force_all', action='store_true', dest='forceAll', help='Force all points to be used.')
    outputSettings.add_argument('--polar_cutoff', type=float, dest='polarCutoff',default=50, help='Binary cutoff for polar.')
    outputSettings.add_argument('--outputMatlab',action='store_true',dest='outputMatlab',help='Outputs a matlab matrix for use in Babelcalib.')
    outputSettings.add_argument('--save_dir', type=str, dest='saveDir',default='/data/', help='All the data will be logged to this directory.')
    outputSettings.add_argument('--log_dest', type=str, dest='logDest',default='log', help='Name (prefix) of log files.')
    outputSettings.add_argument('--debug_image_dir', type=str, dest='debugImageDir', default='', help='Directory for saving debug images for analysis.')

    # Print help if no argument is specified
    if len(sys.argv)==1:
        parser.print_help()
        sys.exit(2)

    # Parse the argument list
    try:
        parsed = parser.parse_args()
    except:
        sys.exit(2)

    # Checks required for TartanCalib to run.
    if len(parsed.topics) != len(parsed.models):
        sm.logError("Please specify exactly one camera model (--models) for each topic (--topics).")
        sys.exit(2)

    if parsed.minViewOutlier<1:
        sm.logError("Please specify a positive integer (--min-views-outlier).")
        sys.exit(2)

    # There is an issue with the gtk plot widget where we cannot plot if we have opencv windows open.
    # Disable plots in this special situation.
    if parsed.showextraction or parsed.verbose:
        parsed.dontShowReport = True

    return parsed

def _binned_stat(uv, values, img_w, img_h, bins=40, stat='mean'):
    """Bin scattered (u,v) data into a 2D grid, aggregating with `stat`."""
    from scipy.stats import binned_statistic_2d
    finite = np.isfinite(values)
    if finite.sum() == 0:
        return np.zeros((bins, bins)), np.linspace(0, img_w, bins+1), np.linspace(0, img_h, bins+1)
    ret = binned_statistic_2d(
        uv[finite, 0], uv[finite, 1], values[finite],
        statistic=stat, bins=bins,
        range=[[0, img_w], [0, img_h]])
    H = ret.statistic.copy()
    H[np.isnan(H)] = 0
    return H, ret.x_edge, ret.y_edge


def _save_corner_diagnostics(cam, cam_id, topic, observations,
                              img_w, img_h, save_dir, bins=40):
    """Generate corner density + gradient heatmaps and cache raw numpy data."""
    from matplotlib.colors import LogNorm

    all_corners = np.vstack([obs.getCornersImageFrame() for obs in observations])
    per_frame_count = np.array([obs.getCornersImageFrame().shape[0] for obs in observations])

    # --- Figure 1: Corner density (3 panels, same as before) ---
    fig1, axes1 = pl.subplots(1, 3, figsize=(21, 6))
    fig1.suptitle("cam{0} ({1}) — {2} corners from {3} frames".format(
        cam_id, topic, len(all_corners), len(observations)), fontsize=13)

    H_density, xedges, yedges = np.histogram2d(
        all_corners[:, 0], all_corners[:, 1],
        bins=[bins, bins], range=[[0, img_w], [0, img_h]])

    ax = axes1[0]
    im = ax.imshow(H_density.T, origin='upper', cmap='hot', interpolation='bilinear',
                   extent=[0, img_w, img_h, 0], aspect='auto')
    fig1.colorbar(im, ax=ax, label='count')
    ax.set_xlabel('x (px)'); ax.set_ylabel('y (px)')
    ax.set_title('Corner Density Heatmap')

    ax = axes1[1]
    ax.scatter(all_corners[:, 0], all_corners[:, 1], s=0.5, alpha=0.2, c='blue')
    ax.set_xlim(0, img_w); ax.set_ylim(img_h, 0)
    ax.set_xlabel('x (px)'); ax.set_ylabel('y (px)')
    ax.set_title('All Detected Corners')
    ax.set_aspect('equal')

    ax = axes1[2]
    ax.hist(per_frame_count, bins=30, color='steelblue', edgecolor='black')
    ax.axvline(np.median(per_frame_count), color='red', linestyle='--',
               label='median={:.0f}'.format(np.median(per_frame_count)))
    ax.set_xlabel('Corners per frame'); ax.set_ylabel('Frame count')
    ax.set_title('Corners-per-frame Distribution')
    ax.legend()

    pl.tight_layout()
    p1 = os.path.join(save_dir, 'cam{0}_corner_heatmap.png'.format(cam_id))
    fig1.savefig(p1, dpi=150); pl.close(fig1)
    print("\tCorner heatmap saved to: {0}".format(p1))

    # --- Collect raw cache dict ---
    raw = {
        "cam_id": cam_id,
        "topic": topic,
        "img_w": img_w,
        "img_h": img_h,
        "all_corners": all_corners,
        "per_frame_count": per_frame_count,
        "H_density": H_density,
        "H_density_xedges": xedges,
        "H_density_yedges": yedges,
    }

    # --- Figure 2: Per-stage gradient diagnostics ---
    stages = getattr(cam, '_diag_per_stage', {})
    for stage_name, diag in stages.items():
        uv = diag["uv"]
        reproj_err = diag["reproj_err"]
        jp_norm = diag["jp_norm"]
        grad_contrib = diag["grad_contrib"]

        if len(uv) == 0:
            continue

        fig2, axes2 = pl.subplots(2, 2, figsize=(16, 12))
        fig2.suptitle("cam{0} ({1}) — stage={2}  N={3}".format(
            cam_id, topic, stage_name, len(uv)), fontsize=13)

        finite_err = reproj_err[np.isfinite(reproj_err)]
        finite_jp = jp_norm[np.isfinite(jp_norm)]
        finite_gc = grad_contrib[np.isfinite(grad_contrib)]

        # (0,0) Reprojection error scatter (log color)
        ax = axes2[0, 0]
        fe = np.abs(reproj_err).copy()
        fe[~np.isfinite(fe)] = np.nan
        fe_clip = np.clip(fe, 1e-3, None)
        sc = ax.scatter(uv[:, 0], uv[:, 1], c=fe_clip, s=0.6, alpha=0.4,
                        cmap='plasma', norm=LogNorm(vmin=max(np.nanpercentile(fe_clip, 1), 1e-2),
                                                    vmax=np.nanpercentile(fe_clip, 99)))
        fig2.colorbar(sc, ax=ax, label='|reproj err|')
        ax.set_xlim(0, img_w); ax.set_ylim(img_h, 0)
        ax.set_xlabel('x (px)'); ax.set_ylabel('y (px)')
        ax.set_title('Reprojection Error (per corner)')
        ax.set_aspect('equal')

        # (0,1) Jacobian norm scatter (log color)
        ax = axes2[0, 1]
        jn = jp_norm.copy()
        jn[~np.isfinite(jn)] = np.nan
        jn_clip = np.clip(jn, 1e-3, None)
        sc = ax.scatter(uv[:, 0], uv[:, 1], c=jn_clip, s=0.6, alpha=0.4,
                        cmap='plasma', norm=LogNorm(vmin=max(np.nanpercentile(jn_clip, 1), 1e-2),
                                                    vmax=np.nanpercentile(jn_clip, 99)))
        fig2.colorbar(sc, ax=ax, label='||J_p||_F')
        ax.set_xlim(0, img_w); ax.set_ylim(img_h, 0)
        ax.set_xlabel('x (px)'); ax.set_ylabel('y (px)')
        ax.set_title('Projection Jacobian Norm ||∂π/∂p||')
        ax.set_aspect('equal')

        # (1,0) Gradient contribution scatter (log color)
        ax = axes2[1, 0]
        gc = grad_contrib.copy()
        gc[~np.isfinite(gc)] = np.nan
        gc_clip = np.clip(gc, 1e-3, None)
        sc = ax.scatter(uv[:, 0], uv[:, 1], c=gc_clip, s=0.6, alpha=0.4,
                        cmap='plasma', norm=LogNorm(vmin=max(np.nanpercentile(gc_clip, 1), 1e-2),
                                                    vmax=np.nanpercentile(gc_clip, 99)))
        fig2.colorbar(sc, ax=ax, label='|err| · ||J||')
        ax.set_xlim(0, img_w); ax.set_ylim(img_h, 0)
        ax.set_xlabel('x (px)'); ax.set_ylabel('y (px)')
        ax.set_title('Gradient Contribution |e|·||J||')
        ax.set_aspect('equal')

        # (1,1) Gradient contribution binned heatmap
        ax = axes2[1, 1]
        H_gc, xe, ye = _binned_stat(uv, grad_contrib, img_w, img_h, bins=bins, stat='mean')
        H_gc_plot = H_gc.T.copy()
        H_gc_plot[H_gc_plot <= 0] = np.nan
        im = ax.imshow(H_gc_plot, origin='upper', cmap='inferno', interpolation='bilinear',
                       extent=[0, img_w, img_h, 0], aspect='auto',
                       norm=LogNorm(vmin=max(np.nanmin(H_gc_plot[H_gc_plot > 0]), 1e-2)
                                    if np.any(H_gc_plot > 0) else 1e-2,
                                    vmax=np.nanmax(H_gc_plot) if np.any(np.isfinite(H_gc_plot)) else 1))
        fig2.colorbar(im, ax=ax, label='mean |e|·||J||')
        ax.set_xlabel('x (px)'); ax.set_ylabel('y (px)')
        ax.set_title('Gradient Contribution Heatmap (binned)')

        pl.tight_layout()
        p2 = os.path.join(save_dir, 'cam{0}_gradient_{1}.png'.format(cam_id, stage_name))
        fig2.savefig(p2, dpi=150); pl.close(fig2)
        print("\tGradient diagnostics ({0}) saved to: {1}".format(stage_name, p2))

        # Binned heatmaps for error and Jacobian too
        H_err, _, _ = _binned_stat(uv, np.abs(reproj_err), img_w, img_h, bins=bins, stat='mean')
        H_jp, _, _ = _binned_stat(uv, jp_norm, img_w, img_h, bins=bins, stat='mean')

        raw["diag_{0}_uv".format(stage_name)] = uv
        raw["diag_{0}_reproj_err".format(stage_name)] = reproj_err
        raw["diag_{0}_jp_norm".format(stage_name)] = jp_norm
        raw["diag_{0}_grad_contrib".format(stage_name)] = grad_contrib
        raw["diag_{0}_proj_params".format(stage_name)] = diag["proj_params"]
        raw["diag_{0}_dist_params".format(stage_name)] = diag["dist_params"]
        raw["diag_{0}_H_err".format(stage_name)] = H_err
        raw["diag_{0}_H_jp".format(stage_name)] = H_jp
        raw["diag_{0}_H_gc".format(stage_name)] = H_gc

        # Weight map visualization (if present)
        wmap = diag.get("weight_map", None)
        per_corner_weight = diag.get("weight", None)
        if wmap is not None:
            fig_w, axes_w = pl.subplots(1, 2, figsize=(14, 5))
            fig_w.suptitle("cam{0} ({1}) — Weight Map  stage={2}".format(
                cam_id, topic, stage_name), fontsize=13)

            ax = axes_w[0]
            im = ax.imshow(wmap, origin='upper', cmap='RdYlGn', interpolation='nearest',
                           extent=[0, img_w, img_h, 0], aspect='auto', vmin=0, vmax=1)
            fig_w.colorbar(im, ax=ax, label='weight [0, 1]')
            ax.set_xlabel('x (px)'); ax.set_ylabel('y (px)')
            ax.set_title('Weight Map (grid={0}px)'.format(
                diag.get("weight_map", np.array([])).shape))

            ax = axes_w[1]
            if per_corner_weight is not None and len(per_corner_weight) > 0:
                sc = ax.scatter(uv[:, 0], uv[:, 1], c=per_corner_weight, s=0.6, alpha=0.4,
                                cmap='RdYlGn', vmin=0, vmax=1)
                fig_w.colorbar(sc, ax=ax, label='weight [0, 1]')
            ax.set_xlim(0, img_w); ax.set_ylim(img_h, 0)
            ax.set_xlabel('x (px)'); ax.set_ylabel('y (px)')
            ax.set_title('Per-corner Weight')
            ax.set_aspect('equal')

            pl.tight_layout()
            pw = os.path.join(save_dir, 'cam{0}_weightmap_{1}.png'.format(cam_id, stage_name))
            fig_w.savefig(pw, dpi=150); pl.close(fig_w)
            print("\tWeight map ({0}) saved to: {1}".format(stage_name, pw))

            raw["diag_{0}_weight_map".format(stage_name)] = wmap
        if per_corner_weight is not None:
            raw["diag_{0}_weight".format(stage_name)] = per_corner_weight

        # --- Camera pose visualization ---
        pose_t_data = diag.get("pose_translations", None)
        pose_rv_data = diag.get("pose_rotations_rotvec", None)
        if pose_t_data is not None and len(pose_t_data) > 0:
            valid_mask = np.isfinite(pose_t_data).all(axis=1)
            pt_valid = pose_t_data[valid_mask]
            if len(pt_valid) > 0:
                try:
                    import mpl_toolkits.mplot3d  # noqa: ensure 3d projection is registered
                    fig_p = pl.figure(figsize=(18, 10))
                    fig_p.suptitle(
                        "cam{0} ({1}) — Init Camera Poses  stage={2}  N={3}/{4}".format(
                            cam_id, topic, stage_name, len(pt_valid), len(pose_t_data)),
                        fontsize=13)

                    dists = np.linalg.norm(pt_valid, axis=1)

                    # (1) 3-D scatter
                    ax3d = fig_p.add_subplot(2, 3, 1, projection='3d')
                    sc3d = ax3d.scatter(
                        pt_valid[:, 0], pt_valid[:, 1], pt_valid[:, 2],
                        c=dists, cmap='plasma', s=12, alpha=0.6)
                    fig_p.colorbar(sc3d, ax=ax3d, label='dist (m)', shrink=0.55, pad=0.1)
                    ax3d.scatter([0], [0], [0], c='red', s=80, marker='*',
                                 zorder=5, label='Target origin')
                    ax3d.set_xlabel('X (m)', labelpad=4)
                    ax3d.set_ylabel('Y (m)', labelpad=4)
                    ax3d.set_zlabel('Z (m)', labelpad=4)
                    ax3d.set_title('3-D Camera Positions\n(target frame)')
                    ax3d.legend(fontsize=7)

                    # (2) Top view XY  (colored by Z)
                    ax_xy = fig_p.add_subplot(2, 3, 2)
                    sc_xy = ax_xy.scatter(
                        pt_valid[:, 0], pt_valid[:, 1],
                        c=pt_valid[:, 2], cmap='plasma', s=10, alpha=0.7)
                    fig_p.colorbar(sc_xy, ax=ax_xy, label='Z (m)')
                    ax_xy.scatter([0], [0], c='red', s=60, marker='*', zorder=5)
                    ax_xy.set_xlabel('X (m)'); ax_xy.set_ylabel('Y (m)')
                    ax_xy.set_title('Top View (XY plane)')
                    ax_xy.set_aspect('equal'); ax_xy.grid(True, alpha=0.3)

                    # (3) Side view XZ  (colored by Y)
                    ax_xz = fig_p.add_subplot(2, 3, 3)
                    sc_xz = ax_xz.scatter(
                        pt_valid[:, 0], pt_valid[:, 2],
                        c=pt_valid[:, 1], cmap='viridis', s=10, alpha=0.7)
                    fig_p.colorbar(sc_xz, ax=ax_xz, label='Y (m)')
                    ax_xz.scatter([0], [0], c='red', s=60, marker='*', zorder=5)
                    ax_xz.set_xlabel('X (m)'); ax_xz.set_ylabel('Z (m)')
                    ax_xz.set_title('Side View (XZ plane)')
                    ax_xz.set_aspect('equal'); ax_xz.grid(True, alpha=0.3)

                    # (4) Distance histogram
                    ax_dist = fig_p.add_subplot(2, 3, 4)
                    ax_dist.hist(dists, bins=30, color='steelblue', edgecolor='black')
                    ax_dist.axvline(np.median(dists), color='red', linestyle='--',
                                    label='median={:.3f} m'.format(np.median(dists)))
                    ax_dist.axvline(np.mean(dists), color='orange', linestyle=':',
                                    label='mean={:.3f} m'.format(np.mean(dists)))
                    ax_dist.set_xlabel('Distance (m)'); ax_dist.set_ylabel('Frame count')
                    ax_dist.set_title('Camera-to-Target Distance Distribution')
                    ax_dist.legend(fontsize=8); ax_dist.grid(True, alpha=0.3)

                    # (5) Rotation angle histogram
                    ax_rot = fig_p.add_subplot(2, 3, 5)
                    if pose_rv_data is not None:
                        rv_valid = pose_rv_data[valid_mask]
                        if rv_valid.shape[0] > 0 and not np.all(np.isnan(rv_valid)):
                            rot_angles_deg = np.rad2deg(
                                np.linalg.norm(rv_valid, axis=1))
                            rot_angles_deg = rot_angles_deg[np.isfinite(rot_angles_deg)]
                            ax_rot.hist(rot_angles_deg, bins=30,
                                        color='darkorange', edgecolor='black')
                            ax_rot.axvline(np.median(rot_angles_deg), color='red',
                                           linestyle='--',
                                           label='median={:.1f}°'.format(
                                               np.median(rot_angles_deg)))
                            ax_rot.set_xlabel('Rotation angle (deg)')
                            ax_rot.set_ylabel('Frame count')
                            ax_rot.set_title('Camera Rotation Angle Distribution')
                            ax_rot.legend(fontsize=8); ax_rot.grid(True, alpha=0.3)

                    # (6) Stats text
                    ax_txt = fig_p.add_subplot(2, 3, 6)
                    ax_txt.axis('off')
                    stats_txt = (
                        "Pose Statistics  [{stage}]\n\n"
                        "Valid poses : {nv} / {nt}\n\n"
                        "X : [{xmin:.3f},  {xmax:.3f}] m   σ={xstd:.3f}\n"
                        "Y : [{ymin:.3f},  {ymax:.3f}] m   σ={ystd:.3f}\n"
                        "Z : [{zmin:.3f},  {zmax:.3f}] m   σ={zstd:.3f}\n\n"
                        "Distance:\n"
                        "  min    = {dmin:.3f} m\n"
                        "  max    = {dmax:.3f} m\n"
                        "  median = {dmed:.3f} m\n"
                        "  mean   = {dmean:.3f} m\n"
                        "  std    = {dstd:.3f} m"
                    ).format(
                        stage=stage_name,
                        nv=len(pt_valid), nt=len(pose_t_data),
                        xmin=pt_valid[:,0].min(), xmax=pt_valid[:,0].max(),
                        xstd=pt_valid[:,0].std(),
                        ymin=pt_valid[:,1].min(), ymax=pt_valid[:,1].max(),
                        ystd=pt_valid[:,1].std(),
                        zmin=pt_valid[:,2].min(), zmax=pt_valid[:,2].max(),
                        zstd=pt_valid[:,2].std(),
                        dmin=dists.min(), dmax=dists.max(),
                        dmed=float(np.median(dists)),
                        dmean=dists.mean(), dstd=dists.std(),
                    )
                    ax_txt.text(0.05, 0.95, stats_txt,
                                transform=ax_txt.transAxes, fontsize=9,
                                verticalalignment='top', fontfamily='monospace',
                                bbox=dict(boxstyle='round', facecolor='wheat',
                                          alpha=0.5))

                    pl.tight_layout()
                    pp = os.path.join(
                        save_dir,
                        'cam{0}_poses_{1}.png'.format(cam_id, stage_name))
                    fig_p.savefig(pp, dpi=150); pl.close(fig_p)
                    print("\tPose visualization ({0}) saved to: {1}".format(
                        stage_name, pp))

                    raw["diag_{0}_pose_translations".format(stage_name)] = pose_t_data
                    if pose_rv_data is not None:
                        raw["diag_{0}_pose_rotvecs".format(stage_name)] = pose_rv_data

                except Exception as _pe:
                    import traceback
                    print("\t[WARN] Pose visualization failed: {0}".format(_pe))
                    traceback.print_exc()

    # --- Save raw cache ---
    npz_path = os.path.join(save_dir, 'cam{0}_diag_raw.npz'.format(cam_id))
    np.savez_compressed(npz_path, **raw)
    print("\tRaw diagnostic data saved to: {0}".format(npz_path))


def main():
    parsed = parseArgs()

    # Perform check for saveDir / debugImageDir upfront.
    if (not os.path.exists(parsed.saveDir)):
        try:
            os.makedirs(parsed.saveDir)
        except:
            print("[ERROR] Unable to create directory in:{}".format(parsed.saveDir))
            raise(OSError)

    if (parsed.debugImageDir != "" and not os.path.exists(parsed.debugImageDir)):
        try:
            os.makedirs(parsed.debugImageDir)
        except:
            print("[ERROR] Unable to create directory in:{}".format(parsed.debugImageDir))
            raise(OSError)

    # Logging modes (verbosity)
    if parsed.verbose:
        sm.setLoggingLevel(sm.LoggingLevel.Debug)
    else:
        sm.setLoggingLevel(sm.LoggingLevel.Info)

    # Argparse has issues with default value being a list which requires additional attention (https://bugs.python.org/issue16399).
    if parsed.l_fov is None:
        parsed.l_fov = DEFAULT_FOV
    if parsed.l_pose is None:
        parsed.l_pose = DEFAULT_POSE
    if parsed.l_res is None:
        parsed.l_res = DEFAULT_RESOLUTION
    
    # Un-nesting list if arguments were supplied from argparser as argparser always nests list.
    if parsed.l_proj is None:
        projections = DEFAULT_PROJECTION
    else:
        projections = parsed.l_proj[0]
    if parsed.l_debug is None:
        debug_modes = DEFAULT_DEBUG_MODES
    else:
        debug_modes = parsed.l_debug[0]

    # Setting up numpy arrays for TartanCalibWorker
    # TODO: Implement checks for number of values / if np arrayable.
    fovs = np.array(parsed.l_fov)
    poses = np.array(parsed.l_pose)
    resolutions = np.array(parsed.l_res)

    # Checking for validity in projections / debug_modes.
    for projection in projections:
        assert(projection in REPROJECTION_MODES)    
    for debug in debug_modes:
        assert(debug in DEBUG_MODES)

    #register signal handler
    signal.signal(signal.SIGINT, signal_exit)

    targetConfig = kc.CalibrationTargetParameters(parsed.targetYaml)

    #create camera objects, initialize the intrinsics and extract targets
    cameraList = list()
    numCams = len(parsed.topics)

    obsdb = kcc.ObservationDatabase(parsed.max_delta_approxsync)
    obslist = list()

    for cam_id in range(numCams):
        topic = parsed.topics[cam_id]
        modelName = parsed.models[cam_id]
        print("Initializing cam{0}:".format(cam_id))
        print("\tCamera model:\t  {0}".format(modelName))

        if modelName in cameraModels:
            #open dataset
            dataset = initBagDataset(parsed.bagfile, topic, parsed.bag_from_to)

            #create camera
            cameraModel = cameraModels[modelName]
            extraction_dir = os.path.join(parsed.saveDir, 'calibration_corners')
            cam = kcc.CameraGeometry(cameraModel, targetConfig, dataset, verbose=(parsed.verbose or parsed.showextraction),
                                     cam_id=cam_id, extraction_dir=extraction_dir)

            #extract the targets
            multithreading = not (parsed.verbose or parsed.showextraction)
            observations = kc.extractCornersFromDataset(cam.dataset, cam.ctarget.detector,
                                                        multithreading=multithreading, clearImages=False,
                                                        noTransformation=True,
                                                        precomputed_detections_file=parsed.precomputedDetections,
                                                        conf_thr=parsed.fisheyeConfThr,
                                                        min_corners=parsed.fisheyeMinCorners)
            #populate the database
            for obs in observations:
                obsdb.addObservation(cam_id, obs)

            obslist.append(observations)

            img_w = int(observations[0].imCols())
            img_h = int(observations[0].imRows())
            print("\tImage resolution: {0} x {1}".format(img_w, img_h))

            #initialize the intrinsics
            cam.weight_map_grid    = parsed.weightMapGrid
            cam.weight_map_power   = parsed.weightMapPower
            cam.weight_map_cutoff  = parsed.weightMapCutoff
            init_success = cam.initGeometryFromObservations(observations)

            # Generate all diagnostics (corner density + gradient heatmaps + raw data)
            try:
                _save_corner_diagnostics(cam, cam_id, topic, observations,
                                         img_w, img_h, parsed.saveDir)
            except Exception as e:
                import traceback
                print("\t[WARN] Corner diagnostics generation failed: {0}".format(e))
                traceback.print_exc()

            if not init_success:
                raise RuntimeError("Could not initialize the intrinsics for camera with topic: {0}. Try to use --verbose and check whether the calibration target extraction is successful.".format(topic))

            print("\tProjection initialized to: %s" % cam.geometry.projection().getParameters().flatten())
            print("\tDistortion initialized to: %s" % cam.geometry.projection().distortion().getParameters().flatten())



            cameraList.append(cam)
        else:
            raise RuntimeError( "Unknown camera model: {0}. Try {1}.".format(modelName, list(cameraModels.keys())) )

    if parsed.verbose:
        obsdb.printTable()

    #initialize the calibration graph
    graph = kcc.MulticamCalibrationGraph(obsdb)

    if not graph.isGraphConnected():
        obsdb.printTable()
        print("Cameras are not connected through mutual observations, please check the dataset. Maybe adjust the approx. sync. tolerance.")
        graph.plotGraph()
        sys.exit(-1)

    #loop to restart the optimization

    obslistTartan = copy.deepcopy(obslist)

    num_iterations = 2
    for iteration in range(num_iterations):
        restartAttempts=100
        initOutlierRejection=True
        removedOutlierCorners=list()

        while True:
            try:
                obsdb_init = copy.deepcopy(obsdb)
                #compute initial guesses for the baselines, intrinsics
                print("initializing initial guesses")
                if len(cameraList)>1:
                    baseline_guesses = graph.getInitialGuesses(cameraList)
                else:
                    baseline_guesses=[]

                if parsed.verbose and len(cameraList)>1:
                    graph.plotGraph()

                for baseline_idx, baseline in enumerate(baseline_guesses):
                    print("initialized baseline between cam{0} and cam{1} to:".format(baseline_idx, baseline_idx+1))
                    print(baseline.T())

                for cam_idx, cam in enumerate(cameraList):
                    print("initialized cam{0} to:".format(cam_idx))
                    print("\t projection cam{0}: {1}".format(cam_idx, cam.geometry.projection().getParameters().flatten()))
                    print("\t distortion cam{0}: {1}".format(cam_idx, cam.geometry.projection().distortion().getParameters().flatten()))


                print("initializing calibrator")
                polar_object = kcc.PolarWeighting()

                # if iteration > 0:
                if parsed.polarSetting == 1:
                    polar_object.mode = kcc.PolarOptions.CUTOFF
                    polar_object.binaryCutOff = parsed.polarCutoff

                elif parsed.polarSetting == 2:
                    polar_object.mode = kcc.PolarOptions.RAND_BIN_PICK
                    polar_object.numBins = 50

                calibrator = kcc.CameraCalibration(cameraList, baseline_guesses, verbose=parsed.verbose, useBlakeZissermanMest=parsed.doBlakeZisserman,polarObject=polar_object)

                if polar_object.mode == kcc.PolarOptions.RAND_BIN_PICK :
                    calibrator.getPolarDistribution(obsdb,kcc.CalibrationTarget(cameraList[0].ctarget.detector.target()),cameraList)

                options = calibrator.estimator.getOptions()
                options.infoGainDelta = parsed.miTol
                options.checkValidity = True
                options.verbose = parsed.verbose
                linearSolverOptions = calibrator.estimator.getLinearSolverOptions()
                linearSolverOptions.columnScaling = True
                linearSolverOptions.verbose = parsed.verbose
                linearSolverOptions.epsSVD = 1e-6
                #linearSolverOptions.svdTol = 0.0 #TODO
                #linearSolverOptions.qrTol = 0.0

                optimizerOptions = calibrator.estimator.getOptimizerOptions()
                optimizerOptions.maxIterations = 50
                optimizerOptions.nThreads = max(1,multiprocessing.cpu_count()-1)
                optimizerOptions.verbose = parsed.verbose
                verbose = parsed.verbose

                doPlot = parsed.plot
                if doPlot:
                    print("Plotting during calibration. Things may be very slow (but you might learn something).")

                #shuffle the views
                timestamps = obsdb.getAllViewTimestamps()
                if not parsed.noShuffle:
                    random.shuffle(timestamps)

                #process all target views
                print("starting calibration...")
                numViews = len(timestamps)
                progress = sm.Progress2(numViews); progress.sample()
                for view_id, timestamp in enumerate(timestamps):
                    #add new batch problem
                    obs_tuple = obsdb.getAllObsAtTimestamp(timestamp)
                    est_baselines = list()
                    for bidx, baseline in enumerate(calibrator.baselines):
                        est_baselines.append( sm.Transformation(baseline.T()) )
                    T_tc_guess = graph.getTargetPoseGuess(timestamp, cameraList, est_baselines)
                    success = False
                    success = calibrator.addTargetView(obs_tuple, T_tc_guess,parsed.forceAll)



                    #display process
                    if (verbose or (view_id % 25) == 0) and calibrator.estimator.getNumBatches()>0 and view_id>1:
                        print("")
                        print("------------------------------------------------------------------")
                        print("")
                        print("Processed {0} of {1} views with {2} views used".format(view_id+1, numViews, calibrator.estimator.getNumBatches()))
                        print("")
                        kcc.printParameters(calibrator)
                        print("")
                        print("------------------------------------------------------------------")

                    #calibration progress
                    progress.sample()

                    #plot added views
                    if success and doPlot:
                        recent_view = calibrator.views[-1]
                        cams_in_view = [obs_tuple[0] for obs_tuple in recent_view.rig_observations]
                        plotter = PlotCollection.PlotCollection("Added view (stamp: {0})".format(timestamp))
                        for cam_id in cams_in_view:
                            fig=pl.figure(view_id*5000+cam_id)
                            kcc.plotAllReprojectionErrors(calibrator, cam_id, fno=fig.number, noShow=True)
                            plotter.add_figure("cam{0}".format(cam_id), fig)
                        plotter.show()

                    # Look for outliers
                    runEndFiltering = view_id==(len(timestamps)-1) and parsed.allowEndFiltering # run another filtering step at the end (over all batches)
                    numActiveBatches = calibrator.estimator.getNumBatches()
                    if ((success and numActiveBatches>parsed.minViewOutlier*numCams) or (runEndFiltering and numActiveBatches>parsed.minViewOutlier*numCams)) and parsed.removeOutliers:
                        #create the list of the batches to check
                        if initOutlierRejection:
                            #check all views after the min. number of batches has been reached
                            batches_to_check=list(range(0, calibrator.estimator.getNumBatches()))
                            print("");print("")
                            print("Filtering outliers in all batches...")
                            initOutlierRejection=False
                            progress_filter = sm.Progress2(len(batches_to_check)); progress_filter.sample()
                        elif runEndFiltering:
                            #check all batches again after all views have been processed
                            print("");print("")
                            print("All views have been processed.\n\nStarting final outlier filtering...")
                            batches_to_check=list(range(0, calibrator.estimator.getNumBatches()))
                            progress_filter = sm.Progress2(len(batches_to_check)); progress_filter.sample()
                        else:
                            #only check most recent view
                            batches_to_check = [ calibrator.estimator.getNumBatches()-1 ]

                        #now check all the specified batches
                        batches_to_check.sort()
                        batches_to_check.reverse()
                        for batch_id in batches_to_check:

                            #check all cameras in this batch
                            cornerRemovalList_allCams=list()
                            camerasInBatch = list(calibrator.views[batch_id].rerrs.keys())
                            for cidx in camerasInBatch:

                                # Calculate the reprojection errors statistics
                                corners, reprojs, rerrs = kcc.getReprojectionErrors(calibrator, cidx)
                                me, se = kcc.getReprojectionErrorStatistics(rerrs)
                                se_threshold = 4.0*se #TODO: find good value

                                #select corners to remove
                                cornerRemovalList=list()
                                for pidx, reproj in enumerate(rerrs[batch_id]):
                                    if (not np.all(reproj==np.array([None,None]))) and (abs(reproj[0]) > se_threshold[0] or abs(reproj[1]) > se_threshold[1]):
                                        cornerRemovalList.append(pidx)

                                        #display the corners info
                                        if parsed.verbose or parsed.doPlotOutliers:
                                            sm.logInfo( "Outlier detected on view {4} with idx {5} (rerr=({0}, {1}) > ({2},{3}) )".format(reproj[0], reproj[1], se_threshold[0], se_threshold[1], view_id, pidx))
                                            sm.logInfo( "Predicted: {0}".format(calibrator.views[batch_id].rerrs[cidx][pidx].getPredictedMeasurement()) )
                                            sm.logInfo( "Measured: {0}".format(calibrator.views[batch_id].rerrs[cidx][pidx].getMeasurement()) )

                                        #store the outlier corners for plotting
                                        removedOutlierCorners.append( (cidx, calibrator.views[batch_id].rerrs[cidx][pidx].getMeasurement()) )

                                #queue corners on this cam for removal
                                cornerRemovalList_allCams.append( (cidx, cornerRemovalList) )

                                #plot the observation with the outliers
                                if len(cornerRemovalList)>0 and parsed.doPlotOutliers:
                                    for cam_id, obs in calibrator.views[batch_id].rig_observations:
                                        if cam_id==cidx:
                                            gridobs = obs
                                    fig=pl.figure(view_id*100+batch_id+cidx)
                                    kcc.plotCornersAndReprojection(gridobs, reprojs[batch_id], cornerlist=cornerRemovalList,
                                                                fno=fig.number, clearFigure=True, plotImage=True,
                                                                title="Removing outliers in view {0} on cam {0}".format(view_id, cidx))
                                    pl.show()

                            #remove the corners (if there are corners to be removed)
                            removeCount = sum([len(removelist) for cidx, removelist in cornerRemovalList_allCams])
                            if removeCount>0:
                                original_batch = calibrator.views[batch_id]
                                new_batch = kcc.removeCornersFromBatch(original_batch, cornerRemovalList_allCams, useBlakeZissermanMest=parsed.doBlakeZisserman,polarObject=polar_object)

                                #replace the original batch with the corrected
                                calibrator.estimator.removeBatch( calibrator.views[batch_id] )
                                calibrator.views[batch_id] = new_batch
                                rval = calibrator.estimator.addBatch( new_batch, parsed.forceAll )

                                #queue the batch for removal if the corrected batch was rejected
                                if not rval.batchAccepted:
                                    sm.logDebug("corrected view rejected! removing from optimization...")
                                    calibrator.views.remove( calibrator.views[batch_id] )
                                sm.logDebug("Removed {0} outlier corners on batch {1}".format(removeCount, batch_id))

                            #start and end filtering progress bar
                            if len(batches_to_check)>1:
                                progress_filter.sample()



                #final output
                print("")
                print("")
                print("..................................................................")
                print("")
                print("Calibration complete.")

                #obsdb_init is the obsdb that was used to train this model
                tartanlogs.append(TartanLogging.TartanLogger(obsdb_init,[copy.deepcopy(cam_.geometry) for cam_ in calibrator.cameras],kcc.getAllPointStatistics(calibrator,0)))


                if (iteration < (num_iterations-1)):
                    obsdb = kcc.ObservationDatabase(parsed.max_delta_approxsync)

                    for cam_id in range(0, numCams):
                        cam = cameraList[cam_id]
                        # This passes all configuration arguments and calls the TartanCalibWorker through CameraGeometry.getProjections
                        # TODO: Parameters should ideally be passed as a struct.
                        tartanParams = [parsed.min_init_corners_autocomplete,
                            parsed.min_tag_size_autocomplete,
                            parsed.correction_threshold,
                            parsed.min_resize_window_size,
                            parsed.max_resize_window_size,
                            parsed.refine_magnitude_reject,
                            parsed.symmetry_refinement,
                            parsed.symmetry_edge_threshold,
                            parsed.export_dataset_dir,
                            parsed.debugImageDir
                        ]
                        
                        new_obs = cam.geometry.getProjections(
                            cam.ctarget.detector,
                            obslistTartan[cam_id],
                            fovs,
                            poses,
                            resolutions,
                            projections,
                            debug_modes,
                            tartanParams
                        )

                        for obs in new_obs:
                            if obs.hasSuccessfulObservation(): # sometime TartanCalib rejects all original (Kalibr) features
                                obsdb.addObservation(cam_id,obs)

                        obslistTartan[cam_id] = new_obs

                    # Saves matlab matrix for use in Babelcalib if outputMatlab option is selected
                    if (parsed.outputMatlab and iteration == (num_iterations-2)):
                        print("Saving to MatLab matrix")
                        timestamps = obsdb.getAllViewTimestamps()
                        # add all observed corners
                        corners_mat = []

                        for view_id, timestamp in enumerate(timestamps):
                            #add new batch problem
                            obs_tuple = obsdb.getAllObsAtTimestamp(timestamp)
                            obs = obs_tuple[0][1]
                            #assumption: only single-cam use
                            x = obs.getCornersImageFrame()
                            x = x.transpose()
                            corner_idxs = obs.getCornersIdx()

                            num_corners = np.shape(x)[1]
                            cspond = np.ones((2,num_corners))
                            # cspond[0,:] = np.arange(1,num_corners+1)
                            # cspond[1,:] = corner_idxs+1
                            cspond[0,:] = corner_idxs+1

                            corners_mat.append({"x":x,"cspond":cspond})

                        # add board definition
                        num_corners = cameraList[0].ctarget.detector.target().size()
                        x_board = np.zeros((2,num_corners))
                        for q in range(num_corners):
                            x_board[0,q] = cameraList[0].ctarget.detector.target().point(q)[0]
                            x_board[1,q] = cameraList[0].ctarget.detector.target().point(q)[1]

                        # identity because we only have one board, so it's at the centre of the global coordinate frame
                        Rt = np.array([[1.0,0,0,0],[0,1.0,0,0],[0,0,1.0,0]])

                        # save corners mat
                        corners_mat_ = np.empty((len(corners_mat),), dtype=np.object)
                        for i in range(len(corners_mat)):
                            corners_mat_[i] = corners_mat[i]
                        scipy.io.savemat('corners.mat',{"corners":corners_mat})

                        # save board def mat
                        scipy.io.savemat('board.mat',{"boards":{"Rt":Rt,"X":x_board}})

                # Initialize the calibration graph
                graph = kcc.MulticamCalibrationGraph(obsdb)

                print("")
                if parsed.removeOutliers:
                    sm.logWarn("Removed {0} outlier corners.".format(len(removedOutlierCorners)) )
                print("")
                print("Processed {0} images with {1} images used".format(numViews, calibrator.estimator.getNumBatches()))
                kcc.printParameters(calibrator)

                if parsed.verbose and len(calibrator.baselines)>1:
                    f=pl.figure(100006)
                    kcc.plotCameraRig(calibrator.baselines, fno=f.number, clearFigure=False)
                    pl.show()

                # Write results to file
                resultFile = os.path.join(parsed.saveDir, parsed.logDest + str(iteration)  + "-camchain.yaml")
                kcc.saveChainParametersYaml(calibrator, resultFile, graph)
                print("Results written to file: {0}".format(resultFile))

                # Write detailed results to file
                resultFileTxt = os.path.join(parsed.saveDir, parsed.logDest + str(iteration) + "-results-cam.txt")
                kcc.saveResultTxt(calibrator, filename=resultFileTxt)
                print("  Detailed results written to file: {0}".format(resultFileTxt))

                # Generate report
                reportFile = os.path.join(parsed.saveDir, parsed.logDest + str(iteration) +"-report-cam.pdf")
                G=None
                if numCams>1:
                    G=graph

                with open(os.path.join(parsed.saveDir, parsed.logDest + '.pkl'), 'wb') as f:
                    dill.dump(tartanlogs, f)

            except kcc.OptimizationDiverged:
                restartAttempts-=1
                sm.logWarn("Optimization diverged possibly due to a bad initialization. (Do the models fit the lenses well?)")

                if restartAttempts==0:
                    sm.logError("Max. attempts reached... Giving up...")
                    break
                else:
                    sm.logWarn("Restarting for a new attempt...")

                    #reinitialize the intrinsics
                    for cam_id, cam in enumerate(cameraList):
                        print("Reinitialize the intrinsics for camera {0}".format(cam_id))
                        observations = obsdb.getAllObsCam(cam_id)
                        if not cam.initGeometryFromObservations(observations):
                            raise RuntimeError("Could not re-initialize the intrinsics for camera with topic: {0}".format(topic))

                        print("\tProjection initialized to: %s" % cam.geometry.projection().getParameters().flatten())
                        print("\tDistortion initialized to: %s" % cam.geometry.projection().distortion().getParameters().flatten())

            else:
                break #normal exit

    kcc.generateReport(calibrator, reportFile, showOnScreen=not parsed.dontShowReport, graph=G, removedOutlierCorners=removedOutlierCorners)

if __name__ == "__main__":
    main()
#     try:
#         main()
#     except Exception,e:
#         sm.logError("Exception: {0}".format(e))
#         sys.exit(-1)
